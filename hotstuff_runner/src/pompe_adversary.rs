// hotstuff_runner/src/pompe.rs
//! å®Œå…¨æ— é”åŒ–çš„Pompe BFTå®ç° - æ”¯æŒcrossbeamæ— é”é˜Ÿåˆ—

use crate::pompe_network::PompeNetwork;
use crossbeam::queue::SegQueue;
use dashmap::DashMap;
use ed25519_dalek::SigningKey;
use hotstuff_rs::types::crypto_primitives::VerifyingKey;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use std::collections::{BTreeMap, HashMap, VecDeque};
use std::net::SocketAddr;
use std::sync::atomic::{AtomicBool, AtomicU64, Ordering};
use std::sync::{Arc, RwLock};
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};
use tokio::sync::mpsc;
use tracing::{debug, error, info, warn};
// Switch Pompe internal queues to tokio::mpsc (async, non-blocking)
use crate::event::SystemEvent;
use tokio::sync::mpsc as async_mpsc;

use crate::pompe::{
    LockFreeHotStuffAdapter,
    // PompeAppState,
    PompeConfig,
    PompeMessage,
    PompeTransaction,
};
#[derive(Debug)]
pub struct PompeAppStateAdversary {
    batch_received: DashMap<String, usize>,
    ordering1_responses: DashMap<String, Vec<u64>>,
    ordering1_count: DashMap<String, usize>,
    completed_ordering1: DashMap<String, ()>,
    ordering2_responses: DashMap<String, Vec<(usize, u64)>>,
    completed_ordering2: DashMap<String, ()>,
    transaction_store: DashMap<String, PompeTransaction>,
    transaction_initiators: DashMap<String, usize>,
    commit_set: Arc<RwLock<Vec<(PompeTransaction, u64)>>>,
    exec_last_batch_clock: Arc<RwLock<u64>>,
    consensus_ready: Arc<RwLock<bool>>,
    stable_point: std::sync::Arc<std::sync::atomic::AtomicU64>,
    // å®šæ—¶åˆ·æ–°ä»»åŠ¡æ˜¯å¦å·²å®‰æ’
    flusher_scheduled: std::sync::atomic::AtomicBool,
}

impl PompeAppStateAdversary {
    fn new() -> Self {
        Self {
            batch_received: DashMap::new(),
            ordering1_responses: DashMap::new(),
            ordering1_count: DashMap::new(),
            completed_ordering1: DashMap::new(),
            ordering2_responses: DashMap::new(),
            completed_ordering2: DashMap::new(),
            transaction_store: DashMap::new(),
            transaction_initiators: DashMap::new(),
            commit_set: Arc::new(RwLock::new(Vec::new())),
            exec_last_batch_clock: Arc::new(RwLock::new(0)),
            consensus_ready: Arc::new(RwLock::new(false)),
            stable_point: Arc::new(std::sync::atomic::AtomicU64::new(0)),
            flusher_scheduled: std::sync::atomic::AtomicBool::new(false),
        }
    }
}

pub fn load_pompe_config() -> PompeConfig {
    use std::env;

    PompeConfig {
        enable: env::var("POMPE_ENABLE")
            .unwrap_or_else(|_| "true".to_string())
            .parse()
            .unwrap_or(true),
        batch_size: env::var("POMPE_BATCH_SIZE")
            .unwrap_or_else(|_| "10".to_string())
            .parse()
            .unwrap_or(1),
        stable_period_ms: env::var("POMPE_STABLE_PERIOD_MS")
            // Keep default conservative for latency: 50ms
            .unwrap_or_else(|_| "50".to_string())
            .parse()
            .unwrap_or(50),
        leader_node_id: env::var("POMPE_LEADER_NODE_ID")
            .unwrap_or_else(|_| "1".to_string())
            .parse()
            .unwrap_or(1),
        liveness_delta_ms: env::var("POMPE_LIVENESS_DELTA_MS")
            .unwrap_or_else(|_| "10".to_string())
            .parse()
            .unwrap_or(10),
        queue_capacity: env::var("POMPE_QUEUE_CAPACITY")
            .unwrap_or_else(|_| "4096".to_string())
            .parse()
            .unwrap_or(4096),
    }
}

pub struct PompeManager {
    node_id: usize,
    config: PompeConfig,
    state: Arc<PompeAppStateAdversary>,
    nfaulty: usize,
    // æ‰€æœ‰èŠ‚ç‚¹åˆ—è¡¨ï¼ˆé¡ºåºéœ€ä¸€è‡´ï¼Œç”¨äºæŒ‰è§†å›¾è½®æ¢ leaderï¼‰
    all_node_ids: Vec<usize>,
    // å½“å‰è§†å›¾å·ä¸æ˜¯å¦ä¸ºå½“å‰è§†å›¾ leader
    current_view: Arc<AtomicU64>,
    is_current_leader: Arc<AtomicBool>,

    ordering1_tx: async_mpsc::Sender<(usize, PompeMessage)>,
    ordering1_rx: Arc<tokio::sync::Mutex<async_mpsc::Receiver<(usize, PompeMessage)>>>,

    ordering2_tx: async_mpsc::Sender<(usize, PompeMessage)>,
    ordering2_rx: Arc<tokio::sync::Mutex<async_mpsc::Receiver<(usize, PompeMessage)>>>,

    general_tx: async_mpsc::Sender<(usize, PompeMessage)>,
    general_rx: Arc<tokio::sync::Mutex<async_mpsc::Receiver<(usize, PompeMessage)>>>,

    // æ–°å¢ï¼šä¸“ç”¨å¹¿æ’­é€šé“ï¼ˆTokio mpscï¼Œé¿å…é˜»å¡ runtime çº¿ç¨‹ï¼‰
    broadcast_tx: async_mpsc::Sender<PompeMessage>,
    broadcast_rx: Arc<tokio::sync::Mutex<Option<async_mpsc::Receiver<PompeMessage>>>>,

    pub network: Option<Arc<crate::pompe_network::PompeNetwork>>,
    lockfree_adapter: Option<Arc<LockFreeHotStuffAdapter>>,
    event_tx: tokio::sync::broadcast::Sender<SystemEvent>,
}

impl PompeManager {
    pub fn get_network(&self) -> Option<&Arc<crate::pompe_network::PompeNetwork>> {
        self.network.as_ref()
    }

    pub async fn get_network_stats(&self) -> Option<(usize, usize)> {
        if let Some(ref network) = self.network {
            Some(network.get_connection_stats().await)
        } else {
            None
        }
    }

    pub fn cleanup_expired_states(&self) {
        if self.state.completed_ordering1.len() > 500 {
            self.state.completed_ordering1.clear();
            debug!(
                "ğŸ§¹ [æ¸…ç†] Node {} æ¸…ç† {} ä¸ªå·²å®Œæˆäº¤æ˜“è®°å½•",
                self.node_id, 500
            );
        }

        let orphan_ordering1 = self.state.ordering1_responses.len();
        if orphan_ordering1 > 500 {
            self.state.ordering1_responses.clear();
            self.state.ordering1_count.clear();
            warn!(
                "ğŸ§¹ [æ¸…ç†] Node {} æ¸…ç† {} ä¸ªå­¤å„¿ordering1çŠ¶æ€",
                self.node_id, orphan_ordering1
            );
        }

        if self.state.transaction_initiators.len() > 1000 {
            self.state.transaction_initiators.clear();
            debug!("ğŸ§¹ [æ¸…ç†] Node {} æ¸…ç†å‘èµ·è€…è®°å½•", self.node_id);
        }

        if self.state.completed_ordering2.len() > 1000 {
            self.state.completed_ordering2.clear();
            debug!("ğŸ§¹ [æ¸…ç†] Node {} æ¸…ç†ordering2å®Œæˆæ ‡è®°", self.node_id);
        }
    }

    pub fn new_with_complete_network(
        node_id: usize,
        all_node_ids: Vec<usize>,
        config: PompeConfig,
        _network: impl hotstuff_rs::networking::network::Network + Clone + Send + 'static,
        event_tx: tokio::sync::broadcast::Sender<SystemEvent>,
    ) -> Self {
        let node_num = all_node_ids.len();
        let nfaulty = (node_num - 1) / 3;
        let (general_tx, general_rx) = async_mpsc::channel(config.queue_capacity);

        info!(
            "ğŸš€ åˆ›å»ºå®Œæ•´ç½‘ç»œæ”¯æŒçš„Pompeç®¡ç†å™¨ï¼ŒèŠ‚ç‚¹ {}, f={}",
            node_id, nfaulty
        );
        info!("ğŸ” èŠ‚ç‚¹åˆ—è¡¨: {:?}", all_node_ids);

        let (ord1_tx, ord1_rx) = async_mpsc::channel(config.queue_capacity);
        let (ord2_tx, ord2_rx) = async_mpsc::channel(config.queue_capacity);
        let (broadcast_tx, broadcast_rx) = async_mpsc::channel(config.queue_capacity);

        let network = Arc::new(PompeNetwork::new(node_id, all_node_ids.clone()));

        Self {
            node_id,
            config,
            state: Arc::new(PompeAppStateAdversary::new()),
            nfaulty,
            all_node_ids: all_node_ids.clone(),
            current_view: Arc::new(AtomicU64::new(0)),
            is_current_leader: Arc::new(AtomicBool::new(false)),
            ordering1_tx: ord1_tx,
            ordering1_rx: Arc::new(tokio::sync::Mutex::new(ord1_rx)),
            ordering2_tx: ord2_tx,
            ordering2_rx: Arc::new(tokio::sync::Mutex::new(ord2_rx)),
            general_tx,
            general_rx: Arc::new(tokio::sync::Mutex::new(general_rx)),
            broadcast_tx,
            broadcast_rx: Arc::new(tokio::sync::Mutex::new(Some(broadcast_rx))),
            network: Some(network),
            lockfree_adapter: None,
            event_tx,
        }
    }

    pub fn set_lockfree_adapter(&mut self, adapter: Arc<LockFreeHotStuffAdapter>) {
        self.lockfree_adapter = Some(adapter);
        info!(
            "âœ… [å®Œå…¨æ— é”è®¾ç½®] Node {} è®¾ç½®æ— é”HotStuffé€‚é…å™¨",
            self.node_id
        );
    }

    pub fn debug_config(&self) {
        info!("ğŸ”§ [é…ç½®æ£€æŸ¥] Node {} Pompeé…ç½®:", self.node_id);
        info!("  - å¯ç”¨çŠ¶æ€: {}", self.config.enable);
        info!("  - æ‰¹æ¬¡å¤§å°: {}", self.config.batch_size);
        info!("  - ç¨³å®šå‘¨æœŸ: {}ms", self.config.stable_period_ms);
        info!("  - é¢†å¯¼è€…èŠ‚ç‚¹: {}", self.config.leader_node_id);
        info!("  - å®¹é”™èŠ‚ç‚¹æ•° f: {}", self.nfaulty);
        info!("  - æ€»èŠ‚ç‚¹æ•°: {}", self.nfaulty * 3 + 1);
        info!("  - éœ€è¦å“åº”æ•° (2f+1): {}", 2 * self.nfaulty + 1);

        if let Some(ref network) = self.network {
            info!("  - ç½‘ç»œèŠ‚ç‚¹åˆ—è¡¨: {:?}", network.peer_node_ids);
            info!(
                "  - å½“å‰èŠ‚ç‚¹åœ¨ç½‘ç»œä¸­: {}",
                network.peer_node_ids.contains(&self.node_id)
            );
        } else {
            warn!("  - âš ï¸ ç½‘ç»œæœªé…ç½®ï¼");
        }
    }

    // Function to process a raw transaction string and call Ordering1
    pub async fn process_raw_transaction(&self, raw_tx: &str) -> Result<(), String> {
        if !self.config.enable {
            debug!("Pompeæœªå¯ç”¨ï¼Œè·³è¿‡: {}", raw_tx);
            return Ok(());
        }

        if let Some(transaction) =
            PompeTransaction::from_raw_string(raw_tx, format!("client_{}", self.node_id))
        {
            let tx_hash = transaction.hash();

            debug!(
                "ğŸ“¥ [Ordering1] Node {} å¤„ç†äº¤æ˜“: {} -> Hash: {}, tx_id={}",
                self.node_id,
                raw_tx,
                &tx_hash[0..8],
                transaction.id
            );

            self.state
                .transaction_store
                .insert(tx_hash.clone(), transaction.clone());

            let current_count = self
                .state
                .batch_received
                .entry(tx_hash.clone())
                .and_modify(|count| *count += 1)
                .or_insert(1)
                .clone();

            debug!(
                "ğŸ“Š [Ordering1] Node {} æ‰¹æ¬¡è®¡æ•°: {} -> {}/{}",
                self.node_id,
                &tx_hash[0..8],
                current_count,
                self.config.batch_size
            );

            if current_count == self.config.batch_size {
                self.state
                    .transaction_initiators
                    .insert(tx_hash.clone(), self.node_id);
                debug!(
                    "ğŸ“‹ [å‘èµ·è€…è®°å½•] Node {} è®°å½•ä¸ºäº¤æ˜“ {} çš„å‘èµ·è€…",
                    self.node_id,
                    &tx_hash[0..8]
                );

                // ä¿®å¤ï¼šè°ƒç”¨æ­£ç¡®çš„æ–¹æ³•
                self.exec_ordering1(tx_hash, transaction).await?;
            } else {
                debug!(
                    "ğŸ”„ [Ordering1] Node {} å·²æœ‰å…¶ä»–èŠ‚ç‚¹å‘èµ·æ­¤äº¤æ˜“çš„ordering",
                    self.node_id
                );
            }
        }

        Ok(())
    }

    async fn exec_ordering1(
        &self,
        tx_hash: String,
        transaction: PompeTransaction,
    ) -> Result<(), String> {
        debug!(
            "ğŸš€ [Ordering1-exec] Node {} å‘èµ·ordering1é˜¶æ®µ: {}",
            self.node_id,
            &tx_hash[0..8]
        );

        let broadcast_start = std::time::Instant::now();

        if let Some(ref network) = self.network {
            let request = PompeMessage::Ordering1Request {
                tx_hash: tx_hash.clone(),
                transaction: transaction.clone(),
                batch_size: self.config.batch_size,
                initiator_node_id: self.node_id,
            };

            // ä½¿ç”¨ä¸“ç”¨å¹¿æ’­é€šé“ï¼ˆæœ‰ç•Œï¼ŒèƒŒå‹ï¼‰
            if let Err(e) = self.broadcast_tx.send(request).await {
                warn!("âš ï¸ [Ordering1-exec] å¹¿æ’­é˜Ÿåˆ—å·²æ»¡/å…³é—­: {}", e);
            }

            let broadcast_duration = broadcast_start.elapsed();
            debug!(
                "â±ï¸ [Ordering1-exec] Node {} å¹¿æ’­è€—æ—¶: {:?}",
                self.node_id, broadcast_duration
            );
        }

        Ok(())
    }

    pub async fn start_network_message_loop(&self) -> Result<(), String> {
        if let Some(ref network) = self.network {
            info!("ğŸš€ Node {} å¯åŠ¨Pompeç½‘ç»œ", self.node_id);

            if let Err(e) = network.start_server() {
                return Err(format!("å¯åŠ¨PompeæœåŠ¡å™¨å¤±è´¥: {}", e));
            }
            // é¢„çƒ­è¿æ¥ï¼Œé™ä½é¦–æ¬¡å‘é€å»¶è¿Ÿ
            network.warm_up_connections();

            // å¯åŠ¨ä¸“ç”¨å¹¿æ’­å¤„ç†å™¨
            let broadcast_rx = {
                let mut rx_guard = self.broadcast_rx.lock().await;
                rx_guard.take()
            };

            if let Some(mut rx) = broadcast_rx {
                let net = Arc::clone(network);
                network.spawn(async move {
                    info!("ğŸ“¡ å¯åŠ¨ä¸“ç”¨å¹¿æ’­å¤„ç†å™¨");
                    while let Some(msg) = rx.recv().await {
                        if let Err(e) = net.broadcast(msg).await {
                            error!("âŒ ä¸“ç”¨å¹¿æ’­å¤±è´¥: {}", e);
                        }
                    }
                });
            }

            // ç›‘å¬ HotStuff è§†å›¾å¼€å§‹äº‹ä»¶ï¼Œè®¡ç®—å½“å‰è§†å›¾ leaderï¼ˆä¿ç•™éå›ºå®š leader æ¨¡å¼ï¼‰
            {
                let mut ev_rx = self.event_tx.subscribe();
                let ids = self.all_node_ids.clone();
                let is_leader = self.is_current_leader.clone();
                let cur_view = self.current_view.clone();
                let my_id = self.node_id;
                tokio::spawn(async move {
                    loop {
                        match ev_rx.recv().await {
                            Ok(SystemEvent::StartView { view }) => {
                                cur_view.store(view, Ordering::SeqCst);
                                if !ids.is_empty() {
                                    let idx = (view as usize) % ids.len();
                                    let leader = ids[idx];
                                    let am_leader = leader == my_id;
                                    is_leader.store(am_leader, Ordering::SeqCst);
                                }
                            }
                            Ok(_) => {}
                            Err(_) => break,
                        }
                    }
                });
            }

            let network_clone = Arc::clone(network);
            let node_id = self.node_id;
            let ordering1_tx = self.ordering1_tx.clone();
            let ordering2_tx = self.ordering2_tx.clone();
            let general_tx = self.general_tx.clone();

            network.spawn(async move {
                info!("ğŸŒ Node {} Pompeæ¶ˆæ¯æ¥æ”¶å¾ªç¯å¯åŠ¨", node_id);
                let mut total_messages = 0;
                let mut ordering1_count = 0;
                let mut ordering2_count = 0;
                
                loop {
                    if let Some((sender_id, message)) = network_clone.recv().await {
                        debug!("ğŸ“¬ [æ¶ˆæ¯æ¥æ”¶] Node {} æ”¶åˆ°æ¥è‡ªèŠ‚ç‚¹ {} çš„æ¶ˆæ¯", node_id, sender_id);
                        total_messages += 1;

                        match &message {
                            PompeMessage::Ordering1Request { .. } | 
                            PompeMessage::Ordering1Response { .. } => {
                                ordering1_count += 1;
                                debug!("ğŸ“¨ [åˆ†å‘å™¨] Node {} åˆ†å‘Ordering1æ¶ˆæ¯: {:?} (æ€»è®¡: O1={}, O2={}, æ€»={})", 
                                    node_id, std::mem::discriminant(&message), ordering1_count, ordering2_count, total_messages);
                                
                                if let Err(e) = ordering1_tx.send((sender_id, message)).await {
                                    error!("âŒ Ordering1é˜Ÿåˆ—å‘é€å¤±è´¥(èƒŒå‹/å…³é—­): {}", e);
                                }
                            }
                            
                            PompeMessage::Ordering2Request { .. } | 
                            PompeMessage::Ordering2Response { .. } => {
                                ordering2_count += 1;
                                debug!("ğŸ“¨ [åˆ†å‘å™¨] Node {} åˆ†å‘Ordering2æ¶ˆæ¯: {:?} (æ€»è®¡: O1={}, O2={}, æ€»={})", 
                                    node_id, std::mem::discriminant(&message), ordering1_count, ordering2_count, total_messages);
                                
                                if let Err(e) = ordering2_tx.send((sender_id, message)).await {
                                    error!("âŒ Ordering2é˜Ÿåˆ—å‘é€å¤±è´¥(èƒŒå‹/å…³é—­): {}", e);
                                }
                            }
                            
                            _ => {
                                if let Err(e) = general_tx.send((sender_id, message)).await {
                                    error!("âŒ é€šç”¨é˜Ÿåˆ—å‘é€å¤±è´¥(èƒŒå‹/å…³é—­): {}", e);
                                }
                            }
                        }
                    }
                }
            });

            self.start_ordering1_processor().await;
            self.start_ordering2_processor().await;
            self.start_general_processor().await;

            // Periodic cleanup of in-memory state to prevent unbounded growth
            let manager_clone = self.clone();
            tokio::spawn(async move {
                let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(30));
                loop {
                    interval.tick().await;
                    manager_clone.cleanup_expired_states();
                }
            });

            // Periodic flusher: tick every stable_period_ms to output stable batch with tail-cut
            let node_id = self.node_id;
            let state = Arc::clone(&self.state);
            let lockfree_adapter = self.lockfree_adapter.clone();
            let config = self.config.clone();
            let network_for_flush = self.network.as_ref().map(|n| Arc::clone(n));
            let is_leader_flag = self.is_current_leader.clone();
            tokio::spawn(async move {
                let mut interval = tokio::time::interval(tokio::time::Duration::from_millis(
                    config.stable_period_ms,
                ));
                loop {
                    interval.tick().await;
                    // ä½¿ç”¨ä¸æ£€æŸ¥è·¯å¾„ç›¸åŒçš„é€»è¾‘
                    if let Some(net) = &network_for_flush {
                        if is_leader_flag.load(Ordering::SeqCst) {
                            // Self::check_and_output_to_hotstuff_lockfree(
                            //     node_id, &state, &lockfree_adapter, &config, net, is_leader_flag.clone()
                            // ).await;
                        }
                    }
                }
            });
        }

        Ok(())
    }

    async fn start_ordering1_processor(&self) {
        let ordering1_rx = Arc::clone(&self.ordering1_rx);
        let state = Arc::clone(&self.state);
        let network = self.network.clone();
        let node_id = self.node_id;
        let nfaulty = self.nfaulty;
        let broadcast_tx = self.broadcast_tx.clone();

        tokio::spawn(async move {
            info!("ğŸ”„ Node {} æ— é”Ordering1å¤„ç†å™¨å¯åŠ¨", node_id);

            loop {
                let message_opt = {
                    let mut rx = ordering1_rx.lock().await;
                    rx.recv().await
                };
                if let Some((sender_id, message)) = message_opt {
                    match message {
                        PompeMessage::Ordering1Request {
                            tx_hash,
                            transaction,
                            batch_size,
                            initiator_node_id,
                        } => {
                            let tx_id = transaction.id;
                            debug!("æ”¶åˆ°Ordering1è¯·æ±‚: {}, hash = {}", tx_id, tx_hash);
                            if let Some(ref net) = network {
                                Self::handle_ordering1_request_lockfree(
                                    node_id,
                                    &state,
                                    &net,
                                    sender_id,
                                    tx_hash,
                                    transaction,
                                    batch_size,
                                    initiator_node_id,
                                )
                                .await;
                            }
                        }
                        PompeMessage::Ordering1Response {
                            tx_hash,
                            timestamp_us,
                            node_id: sender_node_id,
                            initiator_node_id,
                        } => {
                            if let Some(ref net) = network {
                                Self::handle_ordering1_response_lockfree(
                                    node_id,
                                    &state,
                                    nfaulty,
                                    &net,
                                    &broadcast_tx,
                                    sender_id,
                                    tx_hash,
                                    timestamp_us,
                                    sender_node_id,
                                    initiator_node_id,
                                )
                                .await;
                            }
                        }
                        _ => {}
                    }
                }
            }
        });
    }

    async fn start_ordering2_processor(&self) {
        let ordering2_rx = Arc::clone(&self.ordering2_rx);
        let state = Arc::clone(&self.state);
        let network = self.network.clone();
        let node_id = self.node_id;
        let lockfree_adapter = self.lockfree_adapter.clone();
        let config = self.config.clone();
        let event_tx = self.event_tx.clone();
        let is_leader_flag_for_o2 = self.is_current_leader.clone();

        tokio::spawn(async move {
            info!("ğŸ”„ Node {} æ— é”Ordering2å¤„ç†å™¨å¯åŠ¨", node_id);

            loop {
                let message_opt = {
                    let mut rx = ordering2_rx.lock().await;
                    rx.recv().await
                };
                if let Some((sender_id, message)) = message_opt {
                    match message {
                        PompeMessage::Ordering2Request {
                            tx_hash,
                            median_timestamp,
                            initiator_node_id,
                            signatures,
                        } => {
                            if let Some(ref net) = network {
                                Self::handle_ordering2_request_lockfree(
                                    node_id,
                                    &state,
                                    &net,
                                    &lockfree_adapter,
                                    &config,
                                    sender_id,
                                    tx_hash,
                                    median_timestamp,
                                    initiator_node_id,
                                    &event_tx,
                                    is_leader_flag_for_o2.clone(),
                                )
                                .await;
                            }
                        }
                        _ => {}
                    }
                }
            }
        });
    }

    async fn start_general_processor(&self) {
        let general_rx = Arc::clone(&self.general_rx);
        let lockfree_adapter = self.lockfree_adapter.clone();
        let node_id = self.node_id;
        tokio::spawn(async move {
            info!("ğŸ”„ Node {} é€šç”¨æ¶ˆæ¯å¤„ç†å™¨å¯åŠ¨", node_id);
            loop {
                let msg_opt = {
                    let mut rx = general_rx.lock().await;
                    rx.recv().await
                };
                if let Some((_sender_id, message)) = msg_opt {
                    match message {
                        PompeMessage::DeliverOrderedTxs { items, initiator } => {
                            if let Some(ref adapter) = lockfree_adapter {
                                let count = items.len();
                                adapter.push_batch(items);
                                info!("ğŸ“¥ [OrderedæŠ•é€’] Node {} æ¥æ”¶æ¥è‡ª {} çš„å·²æ’åºäº¤æ˜“: {} æ¡ï¼Œå·²å†™å…¥HotStuffé˜Ÿåˆ—", node_id, initiator, count);
                            } else {
                                warn!(
                                    "âš ï¸ [OrderedæŠ•é€’] Node {} æœªè®¾ç½®HotStuffé€‚é…å™¨ï¼Œä¸¢å¼ƒæŠ•é€’",
                                    node_id
                                );
                            }
                        }
                        _ => {}
                    }
                }
            }
        });
    }

    async fn handle_ordering1_request_lockfree(
        node_id: usize,
        state: &Arc<PompeAppStateAdversary>,
        network: &Arc<crate::pompe_network::PompeNetwork>,
        _sender_id: usize,
        tx_hash: String,
        transaction: PompeTransaction,
        _batch_size: usize,
        initiator_node_id: usize,
    ) {
        let processing_start = std::time::Instant::now();

        debug!(
            "ğŸ¯ [handle_ordering1_request] Node {} å¤„ç†è¯·æ±‚: tx_id={}, hash={}",
            node_id,
            transaction.id,
            &tx_hash[0..8]
        );

        let should_respond = if state.ordering1_responses.contains_key(&tx_hash) {
            false
        } else {
            state.transaction_store.insert(tx_hash.clone(), transaction);
            // warn!("âš ï¸ [é¦–æ¬¡Ordering1] Node {} è®°å½•æ–°äº¤æ˜“: hash = {}", node_id, &tx_hash[0..8]);
            state
                .ordering1_responses
                .insert(tx_hash.clone(), Vec::new());
            state.ordering1_count.insert(tx_hash.clone(), 0);
            true
        };

        let check_duration = processing_start.elapsed();
        if check_duration > tokio::time::Duration::from_millis(1) {
            debug!(
                "âš ï¸ [æ£€æŸ¥è€—æ—¶] Node {} Ordering1æ£€æŸ¥è€—æ—¶: {:?}",
                node_id, check_duration
            );
        }

        if !should_respond {
            debug!(
                "ğŸ”„ [handle_ordering1_request] Node {} å·²å“åº”è¿‡: {}",
                node_id,
                &tx_hash[0..8]
            );
            return;
        }

        let timestamp_us = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_micros() as u64;

        let tx_hash_clone = tx_hash.clone();
        let response = PompeMessage::Ordering1Response {
            tx_hash,
            timestamp_us,
            node_id,
            initiator_node_id,
        };

        let network_clone = Arc::clone(network);
        let tx_hash_for_async = tx_hash_clone.clone();
        // tokio::spawn(async move {
        if let Err(e) = network_clone
            .send_to_node(initiator_node_id, response)
            .await
        {
            error!("âŒ [handle_ordering1_request] å¼‚æ­¥å‘é€å¤±è´¥: {}", e);
        }
        info!(
            "ğŸ“¤ [handle_ordering1_request] Node {} å‘é€Ordering1å“åº”ç»™ Node {}: hash = {}",
            node_id, initiator_node_id, tx_hash_for_async
        );
        // });

        let total_duration = processing_start.elapsed();
        if total_duration > tokio::time::Duration::from_millis(5) {
            debug!(
                "âš ï¸ [æ€§èƒ½] Node {} handle_ordering1_requestæ€»è€—æ—¶: {:?}, hash = {}",
                node_id, total_duration, tx_hash_clone
            );
        } else {
            debug!(
                "âœ… [æ€§èƒ½] Node {} handle_ordering1_requestå¤„ç†å®Œæˆ: {:?}, hash = {}",
                node_id, total_duration, tx_hash_clone
            );
        }
    }

    async fn handle_ordering1_response_lockfree(
        node_id: usize,
        state: &Arc<PompeAppStateAdversary>,
        nfaulty: usize,
        network: &Arc<crate::pompe_network::PompeNetwork>,
        broadcast_tx: &mpsc::Sender<PompeMessage>,
        _sender_id: usize,
        tx_hash: String,
        timestamp_us: u64,
        sender_node_id: usize,
        initiator_node_id: usize,
    ) {
        let processing_start = std::time::Instant::now();

        if node_id != initiator_node_id {
            return;
        }

        if state.completed_ordering1.contains_key(&tx_hash) {
            return;
        }

        debug!(
            "ğŸŒŸ [handle_ordering1_response] Node {} æ”¶åˆ°æ—¶é—´æˆ³: {}",
            node_id,
            &tx_hash[0..8]
        );

        let should_proceed = {
            if state.completed_ordering1.contains_key(&tx_hash) {
                return;
            }

            let mut timestamps = state
                .ordering1_responses
                .get(&tx_hash)
                .map(|ref_val| ref_val.clone())
                .unwrap_or_else(Vec::new);

            if timestamps.contains(&timestamp_us) {
                return;
            }

            timestamps.push(timestamp_us);
            let current_count = timestamps.len();

            state
                .ordering1_responses
                .insert(tx_hash.clone(), timestamps.clone());
            state.ordering1_count.insert(tx_hash.clone(), current_count);

            let required = 2 * nfaulty + 1;

            if current_count >= required {
                let mut timestamps_sorted = timestamps;
                timestamps_sorted.sort();
                let median = timestamps_sorted[nfaulty];

                state.completed_ordering1.insert(tx_hash.clone(), ());
                state.ordering1_responses.remove(&tx_hash);
                state.ordering1_count.remove(&tx_hash);

                Some(median)
            } else {
                None
            }
        };

        let processing_duration = processing_start.elapsed();
        if processing_duration > tokio::time::Duration::from_millis(2) {
            debug!("âš ï¸ [å¤„ç†æ€§èƒ½] Node {} handle_ordering1_response å¤„ç†è€—æ—¶: {:?}, æ¥è‡ª Node {}, hash = {}", node_id, processing_duration, sender_node_id, tx_hash);
        } else {
            debug!("âœ… [å¤„ç†æ€§èƒ½] Node {} handle_ordering1_response å¤„ç†å®Œæˆ: {:?}, æ¥è‡ª Node {}, hash = {}", node_id, processing_duration, sender_node_id, tx_hash);
        }

        // warn!("ğŸ˜ˆ [Adversary] Node {} holds Ordering2 Request: hash = {}", node_id, &tx_hash[0..8]);

        // if let Some(median) = should_proceed {
        //     let msg = PompeMessage::Ordering2Request {
        //         tx_hash: tx_hash.clone(),
        //         median_timestamp: median,
        //         initiator_node_id: initiator_node_id,
        //     };

        //     let log_start = std::time::Instant::now();
        //     // ä½¿ç”¨ä¸“ç”¨å¹¿æ’­é€šé“ï¼Œé¿å…é˜»å¡
        //     if let Err(e) = broadcast_tx.send(msg).await {
        //         warn!("âš ï¸ [handle_ordering1_response] å¹¿æ’­é˜Ÿåˆ—èƒŒå‹/å…³é—­: {}", e);
        //     }
        //     let log_duration = log_start.elapsed();
        //     debug!("â±ï¸ [æ€§èƒ½] PompeManager å¹¿æ’­é€šé“å‘é€è€—æ—¶: {:?}, hash = {}", log_duration, tx_hash);
        // }
    }

    // æ˜¯ handle å®Œ ordering 1 response ä¹‹åcallçš„
    async fn handle_ordering2_request_lockfree(
        node_id: usize,
        state: &Arc<PompeAppStateAdversary>,
        network: &Arc<crate::pompe_network::PompeNetwork>,
        lockfree_adapter: &Option<Arc<LockFreeHotStuffAdapter>>,
        config: &PompeConfig,
        _sender_id: usize,
        tx_hash: String,
        median_timestamp: u64,
        initiator_node_id: usize,
        event_tx: &tokio::sync::broadcast::Sender<SystemEvent>,
        is_leader: Arc<AtomicBool>,
    ) {
        let processing_start = std::time::Instant::now();

        debug!(
            "ğŸš€ [Ordering2-2-LockFree] Node {} å¤„ç†è¯·æ±‚: {}",
            node_id,
            &tx_hash[0..8]
        );

        let current_stable_point = state
            .stable_point
            .load(std::sync::atomic::Ordering::Relaxed);

        // Sanity check: the median timestamp should not regress past the stable point
        // dummy check
        if median_timestamp < 0 {
            // if median_timestamp < current_stable_point {
            error!("âŒ [Ordering2-Stableæ£€æŸ¥] Node {} ç½‘ç»œå¼‚å¸¸æ£€æµ‹: median_timestamp({}) < stable_point({})", 
                node_id, median_timestamp, current_stable_point);

            let error_response = PompeMessage::Ordering2Response {
                tx_hash,
                timestamp: 0,
                node_id,
            };

            let network_clone = Arc::clone(network);
            // tokio::spawn(async move {
            if let Err(e) = network_clone
                .send_to_node(initiator_node_id, error_response)
                .await
            {
                error!("âŒ [Ordering2-é”™è¯¯å“åº”] å‘é€å¤±è´¥: {}", e);
            }
            // });

            return;
        }
        info!(
            "âœ… [Ordering2-2-LockFree] Node {} æ£€æŸ¥ç‚¹å¤„ç†å®Œæˆ: stable_point = {}",
            node_id, current_stable_point
        );

        let transaction = match state.transaction_store.get(&tx_hash) {
            Some(tx_ref) => tx_ref.clone(),
            None => {
                // warn!("âš ï¸ [Ordering2-2-LockFree] Node {} æ‰¾ä¸åˆ°äº¤æ˜“: {}", node_id, &tx_hash[0..8]);
                return;
            }
        };

        let tx_id = transaction.id;
        {
            let mut commit_set = state.commit_set.write().unwrap();
            commit_set.push((transaction, median_timestamp));
            drop(commit_set);

            *state.consensus_ready.write().unwrap() = true;
            // Free per-tx state now that it is in the commit pipeline
            state.transaction_store.remove(&tx_hash);
            state.transaction_initiators.remove(&tx_hash);
        }

        let processing_duration = processing_start.elapsed();
        if processing_duration > tokio::time::Duration::from_millis(1) {
            debug!(
                "âš ï¸ [å¤„ç†è€—æ—¶] Node {} Ordering2å¤„ç†è€—æ—¶: {:?}, tx_id={}, hash={}",
                node_id, processing_duration, tx_id, tx_hash
            );
        } else {
            debug!(
                "âœ… [å¤„ç†è€—æ—¶] Node {} Ordering2å¤„ç†è€—æ—¶: {:?}, tx_id={}, hash={}",
                node_id, processing_duration, tx_id, tx_hash
            );
        }

        // if tx_id % 10 == 0 {
        let _ = event_tx.send(SystemEvent::PompeOrdering1Completed { tx_id });
        debug!(
            "ğŸ“¡ [Pompe] Node {} å‘é€ Ordering1 å®Œæˆäº‹ä»¶: tx_id={}",
            node_id, tx_id
        );
        // }

        let response = PompeMessage::Ordering2Response {
            tx_hash,
            timestamp: median_timestamp,
            node_id,
        };

        let network_clone = Arc::clone(network);
        tokio::spawn(async move {
            if let Err(e) = network_clone
                .send_to_node(initiator_node_id, response)
                .await
            {
                error!("âŒ [Ordering2-2-LockFree] å¼‚æ­¥å‘é€å¤±è´¥: {}", e);
            }
        });

        // let state_clone = Arc::clone(state);
        // let lockfree_adapter_clone = lockfree_adapter.clone();
        // let config_clone = config.clone();
        // let network_clone_for_flush = Arc::clone(network);
        if is_leader.load(Ordering::SeqCst) {
            // Self::check_and_output_to_hotstuff_lockfree(
            //     node_id, &state_clone, &lockfree_adapter_clone, &config_clone, &network_clone_for_flush, is_leader.clone()
            // ).await;
        }
    }

    async fn check_and_output_to_hotstuff_lockfree(
        node_id: usize,
        state: &Arc<PompeAppStateAdversary>,
        lockfree_adapter: &Option<Arc<LockFreeHotStuffAdapter>>,
        config: &PompeConfig,
        network: &Arc<crate::pompe_network::PompeNetwork>,
        is_leader: Arc<AtomicBool>,
    ) {
        // é leader ç›´æ¥è¿”å›
        warn!("check_and_output_to_hotstuff_lockfree is triggered!");
        if !is_leader.load(Ordering::SeqCst) {
            return;
        }
        let check_start = std::time::Instant::now();

        let commit_set_len = {
            let commit_set = state.commit_set.read().unwrap();
            commit_set.len()
        };

        let consensus_ready = *state.consensus_ready.read().unwrap();

        if commit_set_len == 0 || !consensus_ready {
            return;
        }

        let current_time_us = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_micros() as u64;

        let ordered_txs = {
            let mut last_batch_clock = state.exec_last_batch_clock.write().unwrap();

            if *last_batch_clock == 0 {
                *last_batch_clock = current_time_us;
                return;
            }

            let time_elapsed = current_time_us - *last_batch_clock;
            let required_wait = config.stable_period_ms * 1000; // 50ms

            if time_elapsed >= required_wait {
                *last_batch_clock = current_time_us;
                drop(last_batch_clock);

                let mut commit_set = state.commit_set.write().unwrap();

                if commit_set.is_empty() {
                    return;
                }

                commit_set.sort_by_key(|&(_, timestamp)| timestamp);

                // æ‰¹æ¬¡å‰ªå°¾: æˆªæ­¢ç‚¹ = æœ€æ–°æ—¶é—´æˆ³ - liveness_delta
                let delta_us = (config.liveness_delta_ms.saturating_mul(1000)) as u64;
                let batch_end_ts = commit_set
                    .last()
                    .map(|&(_, ts)| ts.saturating_sub(delta_us))
                    .unwrap_or(0);

                let mut cut_idx = 0usize;
                while cut_idx < commit_set.len() {
                    if commit_set[cut_idx].1 > batch_end_ts {
                        break;
                    }
                    cut_idx += 1;
                }

                if cut_idx == 0 {
                    // æ²¡æœ‰è¶³å¤Ÿç¨³å®šçš„äº¤æ˜“ï¼Œç­‰å¾…ä¸‹æ¬¡å‘¨æœŸ flush
                    *state.consensus_ready.write().unwrap() = true;
                    return;
                }

                // æ›´æ–° stable_point
                let latest_ts = commit_set[cut_idx - 1].1;
                let old_stable_point = state
                    .stable_point
                    .fetch_max(latest_ts, std::sync::atomic::Ordering::Relaxed);
                info!(
                    "ğŸ“Š [ç¨³å®šç‚¹] Node {} æ›´æ–°stable_point: {} -> {}",
                    node_id, old_stable_point, latest_ts
                );

                let txs: Vec<String> = commit_set
                    .iter()
                    .take(cut_idx)
                    .map(|(tx, timestamp)| tx.to_hotstuff_format(*timestamp))
                    .collect();

                // ç§»é™¤å·²è¾“å‡ºéƒ¨åˆ†
                commit_set.drain(0..cut_idx);
                drop(commit_set);
                *state.consensus_ready.write().unwrap() = false;

                txs
            } else {
                // æœªåˆ°ç¨³å®šæœŸï¼šå®‰æ’ä¸€æ¬¡å®šæ—¶åˆ·æ–°
                let remaining_us = required_wait - time_elapsed;
                if !state
                    .flusher_scheduled
                    .swap(true, std::sync::atomic::Ordering::SeqCst)
                {
                    let state_clone = Arc::clone(state);
                    let lockfree_adapter_clone = lockfree_adapter.clone();
                    let config_clone = config.clone();
                    let network_clone = Arc::clone(network);
                    let leader_flag = is_leader.clone();
                    info!(
                        "â³ [Flusher] Node {} å®‰æ’å®šæ—¶åˆ·æ–°ï¼Œå‰©ä½™ {:?}us",
                        node_id, remaining_us
                    );
                    tokio::spawn(async move {
                        tokio::time::sleep(tokio::time::Duration::from_micros(remaining_us)).await;
                        // åˆ°ç‚¹æ‰§è¡Œä¸€æ¬¡åˆ·æ–°
                        Self::flush_commit_set_to_hotstuff(
                            node_id,
                            &state_clone,
                            &lockfree_adapter_clone,
                            &config_clone,
                            Some(network_clone),
                            leader_flag.clone(),
                        )
                        .await;
                        state_clone
                            .flusher_scheduled
                            .store(false, std::sync::atomic::Ordering::SeqCst);
                    });
                }
                Vec::new()
            }
        };

        let processing_duration = check_start.elapsed();
        if processing_duration > tokio::time::Duration::from_millis(2) {
            debug!(
                "âš ï¸ [è¾“å‡ºè€—æ—¶] Node {} è¾“å‡ºæ£€æŸ¥è€—æ—¶: {:?}",
                node_id, processing_duration
            );
        }

        if !ordered_txs.is_empty() {
            // ä¿®æ”¹ï¼šæ‰€æœ‰èŠ‚ç‚¹å‡å¯æ³¨å…¥åˆ°æœ¬åœ° HotStuff é˜Ÿåˆ—ï¼Œé¿å…é leader äº§ç”Ÿç©ºå—
            if let Some(ref adapter) = lockfree_adapter {
                let cnt = ordered_txs.len();
                adapter.push_batch(ordered_txs.clone());
                info!(
                    "âš¡ [è¾“å‡º] Node {} æ³¨å…¥ {} ä¸ªå·²æ’åºäº¤æ˜“åˆ° HotStuff é˜Ÿåˆ—",
                    node_id, cnt
                );
            } else {
                warn!(
                    "âš ï¸ [è¾“å‡º] Node {} æ— é”é€‚é…å™¨æœªè®¾ç½®ï¼Œä¸¢å¤± {} ä¸ªäº¤æ˜“",
                    node_id,
                    ordered_txs.len()
                );
            }
        }
    }

    async fn flush_commit_set_to_hotstuff(
        node_id: usize,
        state: &Arc<PompeAppStateAdversary>,
        lockfree_adapter: &Option<Arc<LockFreeHotStuffAdapter>>,
        config: &PompeConfig,
        network: Option<Arc<crate::pompe_network::PompeNetwork>>,
        is_leader: Arc<AtomicBool>,
    ) {
        if !is_leader.load(Ordering::SeqCst) {
            return;
        }
        let now_us = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_micros() as u64;
        let mut last_batch_clock = state.exec_last_batch_clock.write().unwrap();
        *last_batch_clock = now_us;
        drop(last_batch_clock);

        let mut commit_set = state.commit_set.write().unwrap();
        if commit_set.is_empty() {
            return;
        }
        commit_set.sort_by_key(|&(_, ts)| ts);
        if let Some(&(_, latest_ts)) = commit_set.last() {
            let old = state
                .stable_point
                .fetch_max(latest_ts, std::sync::atomic::Ordering::Relaxed);
            info!(
                "ğŸ“Š [Flusher] Node {} åˆ·æ–° stable_point: {} -> {} ({} æ¡)",
                node_id,
                old,
                latest_ts,
                commit_set.len()
            );
        }
        let txs: Vec<String> = commit_set
            .iter()
            .map(|(tx, ts)| tx.to_hotstuff_format(*ts))
            .collect();
        commit_set.clear();
        drop(commit_set);
        *state.consensus_ready.write().unwrap() = false;

        // ä¿®æ”¹ï¼šæ‰€æœ‰èŠ‚ç‚¹å‡æ³¨å…¥æœ¬åœ° HotStuff é˜Ÿåˆ—ï¼Œå‡å°‘ç©ºå—æ¦‚ç‡
        if let Some(ref adapter) = lockfree_adapter {
            let count = txs.len();
            adapter.push_batch(txs.clone());
            info!("âš¡ [å®šæ—¶è¾“å‡º] Node {} åˆ·æ–°è¾“å‡º {} ä¸ªäº¤æ˜“", node_id, count);
        } else {
            warn!(
                "âš ï¸ [å®šæ—¶è¾“å‡º] Node {} æ— é”é€‚é…å™¨æœªè®¾ç½®ï¼Œä¸¢å¤± {} ä¸ªäº¤æ˜“",
                node_id,
                txs.len()
            );
        }
    }

    pub fn get_detailed_stats(&self) -> (usize, usize, usize, bool, u64, usize, usize) {
        let batch_count = self.state.batch_received.len();
        let ordering1_count = self.state.ordering1_responses.len();
        let transaction_store_len = self.state.transaction_store.len();
        let transaction_initiators_len = self.state.transaction_initiators.len();

        let commit_set_len = {
            let commit_set = self.state.commit_set.read().unwrap();
            commit_set.len()
        };
        let consensus_ready = *self.state.consensus_ready.read().unwrap();
        let exec_last_batch_clock = *self.state.exec_last_batch_clock.read().unwrap();

        (
            batch_count,
            ordering1_count,
            commit_set_len,
            consensus_ready,
            exec_last_batch_clock,
            transaction_store_len,
            transaction_initiators_len,
        )
    }

    pub fn is_enabled(&self) -> bool {
        self.config.enable
    }

    pub fn clone(&self) -> Self {
        Self {
            node_id: self.node_id,
            config: self.config.clone(),
            state: Arc::clone(&self.state),
            nfaulty: self.nfaulty,
            all_node_ids: self.all_node_ids.clone(),
            current_view: Arc::clone(&self.current_view),
            is_current_leader: Arc::clone(&self.is_current_leader),
            ordering1_tx: self.ordering1_tx.clone(),
            ordering1_rx: Arc::clone(&self.ordering1_rx),
            ordering2_tx: self.ordering2_tx.clone(),
            ordering2_rx: Arc::clone(&self.ordering2_rx),
            general_tx: self.general_tx.clone(),
            general_rx: Arc::clone(&self.general_rx),
            broadcast_tx: self.broadcast_tx.clone(),
            broadcast_rx: Arc::clone(&self.broadcast_rx),
            network: self.network.as_ref().map(|n| Arc::clone(n)),
            lockfree_adapter: self.lockfree_adapter.clone(),
            event_tx: self.event_tx.clone(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_pompe_transaction_parsing() {
        let raw_tx = "123:alice->bob:100";
        let tx = PompeTransaction::from_raw_string(raw_tx, "client_1".to_string());

        assert!(tx.is_some());
        let tx = tx.unwrap();
        assert_eq!(tx.id, 123);
        assert_eq!(tx.from, "alice");
        assert_eq!(tx.to, "bob");
        assert_eq!(tx.amount, 100);
    }

    #[test]
    fn test_transaction_hash() {
        let tx = PompeTransaction {
            id: 1,
            from: "alice".to_string(),
            to: "bob".to_string(),
            amount: 100,
            client_id: "test".to_string(),
            timestamp: 0,
            nonce: 0,
        };
        let hash = tx.hash();
        assert!(!hash.is_empty());
        assert_eq!(hash.len(), 64);
    }

    #[test]
    fn test_hotstuff_format() {
        let tx = PompeTransaction {
            id: 1,
            from: "alice".to_string(),
            to: "bob".to_string(),
            amount: 100,
            client_id: "test".to_string(),
            timestamp: 0,
            nonce: 0,
        };
        let formatted = tx.to_hotstuff_format(1234567890);
        assert!(formatted.starts_with("pompe:1234567890:1:alice->bob:100"));
    }
}
