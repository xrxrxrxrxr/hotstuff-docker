// è¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡ç›‘æ§å®ç°
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use std::time::{Duration, Instant};
use std::collections::VecDeque;
use tokio::sync::Mutex;

#[derive(Debug)]
pub struct DetailedLatencyTracker {
    // å»¶è¿Ÿè®°å½•
    latency_samples: Mutex<VecDeque<Duration>>,
    max_samples: usize,
    
    // è®¡æ•°å™¨
    total_processed: AtomicUsize,
    total_processing_time_nanos: AtomicU64,
    
    // æ—¶é—´æˆ³
    start_time: Instant,
    last_reset_time: AtomicU64,
}

impl DetailedLatencyTracker {
    pub fn new(max_samples: usize) -> Self {
        Self {
            latency_samples: Mutex::new(VecDeque::with_capacity(max_samples)),
            max_samples,
            total_processed: AtomicUsize::new(0),
            total_processing_time_nanos: AtomicU64::new(0),
            start_time: Instant::now(),
            last_reset_time: AtomicU64::new(0),
        }
    }
    
    pub async fn record_processing(&self, processing_time: Duration) {
        // æ›´æ–°è®¡æ•°å™¨
        self.total_processed.fetch_add(1, Ordering::Relaxed);
        self.total_processing_time_nanos.fetch_add(
            processing_time.as_nanos() as u64, 
            Ordering::Relaxed
        );
        
        // è®°å½•æ ·æœ¬
        let mut samples = self.latency_samples.lock().await;
        if samples.len() >= self.max_samples {
            samples.pop_front();
        }
        samples.push_back(processing_time);
    }
    
    pub async fn get_statistics(&self) -> LatencyStatistics {
        let samples = self.latency_samples.lock().await;
        let total_processed = self.total_processed.load(Ordering::Relaxed);
        let total_time_nanos = self.total_processing_time_nanos.load(Ordering::Relaxed);
        
        let elapsed = self.start_time.elapsed();
        let tps = if elapsed.as_secs_f64() > 0.0 {
            total_processed as f64 / elapsed.as_secs_f64()
        } else {
            0.0
        };
        
        let average_latency = if total_processed > 0 {
            Duration::from_nanos(total_time_nanos / total_processed as u64)
        } else {
            Duration::ZERO
        };
        
        // è®¡ç®—æœ€è¿‘å»¶è¿Ÿç»Ÿè®¡
        let recent_statistics = if !samples.is_empty() {
            let mut sorted_samples: Vec<Duration> = samples.iter().cloned().collect();
            sorted_samples.sort();
            
            let len = sorted_samples.len();
            let recent_avg = sorted_samples.iter().sum::<Duration>() / len as u32;
            let recent_p50 = sorted_samples[len / 2];
            let recent_p95 = sorted_samples[(len as f64 * 0.95) as usize];
            let recent_p99 = sorted_samples[(len as f64 * 0.99) as usize];
            let recent_max = *sorted_samples.last().unwrap();
            let recent_min = *sorted_samples.first().unwrap();
            
            Some(RecentLatencyStats {
                avg: recent_avg,
                p50: recent_p50,
                p95: recent_p95,
                p99: recent_p99,
                max: recent_max,
                min: recent_min,
                sample_count: len,
            })
        } else {
            None
        };
        
        LatencyStatistics {
            tps,
            total_processed,
            average_latency,
            recent: recent_statistics,
            elapsed_time: elapsed,
        }
    }
    
    pub async fn reset_recent_samples(&self) {
        let mut samples = self.latency_samples.lock().await;
        samples.clear();
        self.last_reset_time.store(
            self.start_time.elapsed().as_secs(), 
            Ordering::Relaxed
        );
    }
}

#[derive(Debug, Clone)]
pub struct LatencyStatistics {
    pub tps: f64,
    pub total_processed: usize,
    pub average_latency: Duration,
    pub recent: Option<RecentLatencyStats>,
    pub elapsed_time: Duration,
}

#[derive(Debug, Clone)]
pub struct RecentLatencyStats {
    pub avg: Duration,
    pub p50: Duration,
    pub p95: Duration,
    pub p99: Duration,
    pub max: Duration,
    pub min: Duration,
    pub sample_count: usize,
}

// Pompe é˜Ÿåˆ—ä¸“ç”¨æ€§èƒ½ç›‘æ§
#[derive(Debug)]
pub struct PompeQueueMetrics {
    // ä¸åŒé˜¶æ®µçš„å»¶è¿Ÿè·Ÿè¸ª
    pub batch_processing_tracker: DetailedLatencyTracker,
    pub ordering1_tracker: DetailedLatencyTracker,
    pub ordering2_tracker: DetailedLatencyTracker,
    pub commit_tracker: DetailedLatencyTracker,
    
    // é˜Ÿåˆ—å¤§å°è®°å½•
    queue_size_samples: Mutex<VecDeque<(Instant, usize)>>,
    
    // ååé‡ç»Ÿè®¡
    pub transactions_submitted: AtomicUsize,
    pub transactions_completed: AtomicUsize,
    
    start_time: Instant,
}

impl PompeQueueMetrics {
    pub fn new() -> Self {
        Self {
            batch_processing_tracker: DetailedLatencyTracker::new(100),
            ordering1_tracker: DetailedLatencyTracker::new(100),
            ordering2_tracker: DetailedLatencyTracker::new(100),
            commit_tracker: DetailedLatencyTracker::new(100),
            queue_size_samples: Mutex::new(VecDeque::with_capacity(200)),
            transactions_submitted: AtomicUsize::new(0),
            transactions_completed: AtomicUsize::new(0),
            start_time: Instant::now(),
        }
    }
    
    pub async fn record_queue_size(&self, size: usize) {
        let mut samples = self.queue_size_samples.lock().await;
        let now = Instant::now();
        
        if samples.len() >= 200 {
            samples.pop_front();
        }
        samples.push_back((now, size));
    }
    
    pub fn record_transaction_submitted(&self, count: usize) {
        self.transactions_submitted.fetch_add(count, Ordering::Relaxed);
    }
    
    pub fn record_transaction_completed(&self, count: usize) {
        self.transactions_completed.fetch_add(count, Ordering::Relaxed);
    }
    
    pub async fn get_comprehensive_stats(&self) -> PompeQueueStats {
        let batch_stats = self.batch_processing_tracker.get_statistics().await;
        let ordering1_stats = self.ordering1_tracker.get_statistics().await;
        let ordering2_stats = self.ordering2_tracker.get_statistics().await;
        let commit_stats = self.commit_tracker.get_statistics().await;
        
        let submitted = self.transactions_submitted.load(Ordering::Relaxed);
        let completed = self.transactions_completed.load(Ordering::Relaxed);
        let elapsed = self.start_time.elapsed();
        
        let submission_tps = if elapsed.as_secs_f64() > 0.0 {
            submitted as f64 / elapsed.as_secs_f64()
        } else {
            0.0
        };
        
        let completion_tps = if elapsed.as_secs_f64() > 0.0 {
            completed as f64 / elapsed.as_secs_f64()
        } else {
            0.0
        };
        
        // è®¡ç®—å¹³å‡é˜Ÿåˆ—å¤§å°
        let samples = self.queue_size_samples.lock().await;
        let avg_queue_size = if !samples.is_empty() {
            samples.iter().map(|(_, size)| *size).sum::<usize>() as f64 / samples.len() as f64
        } else {
            0.0
        };
        
        PompeQueueStats {
            submission_tps,
            completion_tps,
            submitted_total: submitted,
            completed_total: completed,
            avg_queue_size,
            batch_processing: batch_stats,
            ordering1: ordering1_stats,
            ordering2: ordering2_stats,
            commit: commit_stats,
            elapsed_time: elapsed,
        }
    }
}

#[derive(Debug)]
pub struct PompeQueueStats {
    pub submission_tps: f64,
    pub completion_tps: f64,
    pub submitted_total: usize,
    pub completed_total: usize,
    pub avg_queue_size: f64,
    pub batch_processing: LatencyStatistics,
    pub ordering1: LatencyStatistics,
    pub ordering2: LatencyStatistics,
    pub commit: LatencyStatistics,
    pub elapsed_time: Duration,
}

// HotStuff é˜Ÿåˆ—ä¸“ç”¨æ€§èƒ½ç›‘æ§
#[derive(Debug)]
pub struct HotStuffQueueMetrics {
    pub block_production_tracker: DetailedLatencyTracker,
    pub block_validation_tracker: DetailedLatencyTracker,
    pub consensus_tracker: DetailedLatencyTracker,
    
    // é˜Ÿåˆ—å’ŒåŒºå—ç»Ÿè®¡
    queue_size_samples: Mutex<VecDeque<(Instant, usize)>>,
    pub blocks_produced: AtomicUsize,
    pub blocks_committed: AtomicUsize,
    pub transactions_in_blocks: AtomicUsize,
    
    start_time: Instant,
}

impl HotStuffQueueMetrics {
    pub fn new() -> Self {
        Self {
            block_production_tracker: DetailedLatencyTracker::new(50),
            block_validation_tracker: DetailedLatencyTracker::new(50),
            consensus_tracker: DetailedLatencyTracker::new(50),
            queue_size_samples: Mutex::new(VecDeque::with_capacity(200)),
            blocks_produced: AtomicUsize::new(0),
            blocks_committed: AtomicUsize::new(0),
            transactions_in_blocks: AtomicUsize::new(0),
            start_time: Instant::now(),
        }
    }
    
    pub async fn record_queue_size(&self, size: usize) {
        let mut samples = self.queue_size_samples.lock().await;
        let now = Instant::now();
        
        if samples.len() >= 200 {
            samples.pop_front();
        }
        samples.push_back((now, size));
    }
    
    pub fn record_block_produced(&self, tx_count: usize) {
        self.blocks_produced.fetch_add(1, Ordering::Relaxed);
        self.transactions_in_blocks.fetch_add(tx_count, Ordering::Relaxed);
    }
    
    pub fn record_block_committed(&self, tx_count: usize) {
        self.blocks_committed.fetch_add(1, Ordering::Relaxed);
    }
    
    pub async fn get_comprehensive_stats(&self) -> HotStuffQueueStats {
        let production_stats = self.block_production_tracker.get_statistics().await;
        let validation_stats = self.block_validation_tracker.get_statistics().await;
        let consensus_stats = self.consensus_tracker.get_statistics().await;
        
        let blocks_produced = self.blocks_produced.load(Ordering::Relaxed);
        let blocks_committed = self.blocks_committed.load(Ordering::Relaxed);
        let total_transactions = self.transactions_in_blocks.load(Ordering::Relaxed);
        let elapsed = self.start_time.elapsed();
        
        let block_production_tps = if elapsed.as_secs_f64() > 0.0 {
            blocks_produced as f64 / elapsed.as_secs_f64()
        } else {
            0.0
        };
        
        let transaction_tps = if elapsed.as_secs_f64() > 0.0 {
            total_transactions as f64 / elapsed.as_secs_f64()
        } else {
            0.0
        };
        
        // è®¡ç®—å¹³å‡é˜Ÿåˆ—å¤§å°
        let samples = self.queue_size_samples.lock().await;
        let avg_queue_size = if !samples.is_empty() {
            samples.iter().map(|(_, size)| *size).sum::<usize>() as f64 / samples.len() as f64
        } else {
            0.0
        };
        
        HotStuffQueueStats {
            block_production_tps,
            transaction_tps,
            blocks_produced_total: blocks_produced,
            blocks_committed_total: blocks_committed,
            transactions_total: total_transactions,
            avg_queue_size,
            block_production: production_stats,
            block_validation: validation_stats,
            consensus: consensus_stats,
            elapsed_time: elapsed,
        }
    }
}

#[derive(Debug)]
pub struct HotStuffQueueStats {
    pub block_production_tps: f64,
    pub transaction_tps: f64,
    pub blocks_produced_total: usize,
    pub blocks_committed_total: usize,
    pub transactions_total: usize,
    pub avg_queue_size: f64,
    pub block_production: LatencyStatistics,
    pub block_validation: LatencyStatistics,
    pub consensus: LatencyStatistics,
    pub elapsed_time: Duration,
}

// æ ¼å¼åŒ–è¾“å‡ºå‡½æ•°
pub fn format_duration_micros(duration: Duration) -> String {
    let micros = duration.as_micros();
    if micros < 1000 {
        format!("{}Î¼s", micros)
    } else if micros < 1_000_000 {
        format!("{:.1}ms", micros as f64 / 1000.0)
    } else {
        format!("{:.2}s", micros as f64 / 1_000_000.0)
    }
}

pub fn print_pompe_detailed_stats(node_id: usize, stats: &PompeQueueStats) {
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ“Š [Node {}] Pompeé˜Ÿåˆ—è¯¦ç»†æ€§èƒ½æŠ¥å‘Š", node_id);
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    
    // æ€»ä½“TPS
    println!("ğŸ¯ æ€»ä½“ååé‡:");
    println!("   æäº¤TPS: {:.2} tx/s | å®ŒæˆTPS: {:.2} tx/s | å¹³å‡é˜Ÿåˆ—å¤§å°: {:.1}", 
             stats.submission_tps, stats.completion_tps, stats.avg_queue_size);
    println!("   æ€»æäº¤: {} | æ€»å®Œæˆ: {} | è¿è¡Œæ—¶é—´: {:.1}s", 
             stats.submitted_total, stats.completed_total, stats.elapsed_time.as_secs_f64());
    
    // å„é˜¶æ®µå»¶è¿Ÿ
    println!("\nâ±ï¸ å„é˜¶æ®µå¤„ç†å»¶è¿Ÿ:");
    print_stage_latency("æ‰¹å¤„ç†", &stats.batch_processing);
    print_stage_latency("Ordering1", &stats.ordering1);
    print_stage_latency("Ordering2", &stats.ordering2);
    print_stage_latency("æäº¤", &stats.commit);
}

pub fn print_hotstuff_detailed_stats(node_id: usize, stats: &HotStuffQueueStats) {
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ”¥ [Node {}] HotStuffé˜Ÿåˆ—è¯¦ç»†æ€§èƒ½æŠ¥å‘Š", node_id);
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    
    // æ€»ä½“TPS
    println!("ğŸ¯ æ€»ä½“ååé‡:");
    println!("   åŒºå—TPS: {:.2} blocks/s | äº¤æ˜“TPS: {:.2} tx/s | å¹³å‡é˜Ÿåˆ—å¤§å°: {:.1}", 
             stats.block_production_tps, stats.transaction_tps, stats.avg_queue_size);
    println!("   æ€»åŒºå—: {} | å·²æäº¤: {} | æ€»äº¤æ˜“: {} | è¿è¡Œæ—¶é—´: {:.1}s", 
             stats.blocks_produced_total, stats.blocks_committed_total, 
             stats.transactions_total, stats.elapsed_time.as_secs_f64());
    
    // å„é˜¶æ®µå»¶è¿Ÿ
    println!("\nâ±ï¸ å„é˜¶æ®µå¤„ç†å»¶è¿Ÿ:");
    print_stage_latency("åŒºå—ç”Ÿäº§", &stats.block_production);
    print_stage_latency("åŒºå—éªŒè¯", &stats.block_validation);
    print_stage_latency("å…±è¯†ç¡®è®¤", &stats.consensus);
}

fn print_stage_latency(stage_name: &str, stats: &LatencyStatistics) {
    println!("   ğŸ“ˆ {}: TPS={:.2}, å¹³å‡å»¶è¿Ÿ={}, æ€»å¤„ç†={}", 
             stage_name, stats.tps, format_duration_micros(stats.average_latency), stats.total_processed);
    
    if let Some(recent) = &stats.recent {
        println!("      æœ€è¿‘å»¶è¿Ÿåˆ†å¸ƒ: å¹³å‡={} | P50={} | P95={} | P99={} | æœ€å¤§={} | æ ·æœ¬={}",
                 format_duration_micros(recent.avg),
                 format_duration_micros(recent.p50),
                 format_duration_micros(recent.p95),
                 format_duration_micros(recent.p99),
                 format_duration_micros(recent.max),
                 recent.sample_count);
    }
}